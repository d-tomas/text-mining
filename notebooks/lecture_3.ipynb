{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPv5cygmin3B/gLqmyKmL+u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-tomas/text-mining/blob/main/notebooks/lecture_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1AwPWOa4LTA"
      },
      "source": [
        "# **Day 3**: Supervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vftAQFLq5Qa8"
      },
      "source": [
        "## Initial setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bXm4awKjMGU"
      },
      "source": [
        "# Import the required libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Extract TF-IDF weighting schema\n",
        "from sklearn.feature_extraction.text import CountVectorizer  # Extract TF weighting schema\n",
        "from sklearn.metrics import accuracy_score  # Calculate the accuracy of the classifier\n",
        "from sklearn.metrics import confusion_matrix  # Get the confusion matrix\n",
        "from sklearn.model_selection import cross_val_score  # Cross-validation evaluation\n",
        "from sklearn.model_selection import train_test_split  # Split the dataset into train and test\n",
        "from sklearn.naive_bayes import MultinomialNB  # Na√Øve Bayes algorithm\n",
        "from sklearn.neighbors import KNeighborsClassifier  # k-NN algorithm\n",
        "from sklearn.neural_network import MLPClassifier  # Neural Networks algorithm\n",
        "from sklearn.svm import SVC  # Support Vector Machines algorithm\n",
        "from sklearn.tree import DecisionTreeClassifier  # Decission tree algorithm\n",
        "import spacy\n",
        "\n",
        "# Install the SpaCy model for English texts\n",
        "spacy.cli.download('en_core_web_sm')\n",
        "\n",
        "# Load the model (disable some functionalities not used in these exercises to save processing time)\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner', 'entity_likner', 'entity_ruler'])\n",
        "\n",
        "# Download RePEC corpus\n",
        "!wget https://raw.githubusercontent.com/d-tomas/text-mining/main/datasets/repec_s.csv\n",
        "# Download cell phone opinions corpus\n",
        "!wget https://raw.githubusercontent.com/d-tomas/text-mining/main/datasets/cell_phones.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRO0rlVXlkKW"
      },
      "source": [
        "## Example 1: text classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mqNDDvWlmhw"
      },
      "source": [
        "# Show the first lines of the 'repec_s.csv' file\n",
        "\n",
        "!head repec_s.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et2IrRJsmtIP"
      },
      "source": [
        "# Loading data from file into a Pandas DataFrame\n",
        "\n",
        "data = pd.read_csv('repec_s.csv')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlgNyttpnIR4"
      },
      "source": [
        "# Keep the contents of the abstract for classification\n",
        "\n",
        "corpus = data['abstract']  # Store the abstracts\n",
        "y = data['jel']  # Store the JEL category"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HELdN7HBm5H_"
      },
      "source": [
        "# Plot the number of instances in each class\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.countplot(x=y)\n",
        "plt.show()\n",
        "\n",
        "# F:\tInternational Economics\n",
        "# I:\tHealth, Education, and Welfare\n",
        "# R:\tUrban, Rural, Regional, Real Estate, and Transportation Economics\n",
        "# M:\tBusiness Administration and Business Economics | Marketing | Accounting | Personnel Economics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXreFadJo9B8"
      },
      "source": [
        "# Preprocessing\n",
        "# For each abstract: remove punctuation, remove stopwords, and lowercase\n",
        "\n",
        "def normalise(text):\n",
        "  document = nlp(text)  # Process the text with SpaCy\n",
        "  document = [token for token in document if not token.is_punct]  # Remove punctuation\n",
        "  document = [token for token in document if not token.is_stop]  # Remove stopwords\n",
        "  document = [token.lower_ for token in document]  # Lowercase\n",
        "  return ' '.join(document)\n",
        "\n",
        "corpus_normalised = corpus.map(normalise)\n",
        "corpus_normalised"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgtWyIEFm4b_"
      },
      "source": [
        "# Create a 'classify' function that performs the training and testing\n",
        "# Input parameters:\n",
        "# - corpus: the dataset containing the text for train and test\n",
        "# - model_name: the name of the algorithm that we want to use ('DT', 'KNN', 'MLP', 'NB' or 'SVM')\n",
        "# - evaluation_type: the type of evaluation, train/test split ('split') or cross-validation ('cv)\n",
        "# The function returns the trained model and the vectorizer\n",
        "# Both are required if we want to perform predictions in the future based on this model\n",
        "\n",
        "def classify(corpus, model_name, evaluation_type):\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "  if model_name == 'DT':\n",
        "    model = DecisionTreeClassifier()  # Decission tree\n",
        "  elif model_name == 'KNN':\n",
        "    model = KNeighborsClassifier()  # k-NN\n",
        "  elif model_name == 'MLP':  \n",
        "    model = MLPClassifier()  # Neural network\n",
        "  elif model_name == 'NB':\n",
        "    model = MultinomialNB()  # Na√Øve Bayes\n",
        "  else:\n",
        "    model = SVC(kernel = 'linear')  # SVM\n",
        "\n",
        "  # The user chooses to evaluate with train/test split\n",
        "  if evaluation_type == 'split':\n",
        "    # Split into training (80%) and test (20%)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "    \n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Prediction on the test set\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Calculate the accuracy of the algorithm\n",
        "    print('Accuracy: {:.2%}\\n'.format(accuracy_score(predictions, y_test)))\n",
        "    print('Confusion matrix:')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(confusion_matrix(y_test, predictions), annot=True, linewidth=3)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.show()\n",
        "  # The user chooses to evaluate with k-fold cross validation\n",
        "  elif evaluation_type == 'cv':\n",
        "    scores = cross_val_score(model, X, y, cv=5)  # 5-fold evaluation\n",
        "    print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
        "  else:\n",
        "    print('Unknown evaluation type')\n",
        "  \n",
        "  return model, vectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC_Q2NUmwC6J"
      },
      "source": [
        "# Possible values for model name: DT, KNN, MLP, NB, SVM\n",
        "# Possible values for evaluation type: split, cv\n",
        "# Returns the trained model and the vectorizer for further predictions\n",
        "\n",
        "model_repec, vectorizer_repec = classify(corpus, 'SVM', 'split')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J1cKzL9sGdp"
      },
      "source": [
        "# Prediction for a new (never seen before) sample\n",
        "\n",
        "new_input = ['The prize of bananas and its correlation with global warming']\n",
        "\n",
        "new_input = vectorizer_repec.transform(new_input)  # Transform the new instance following the same procedure used when the model was created\n",
        "label = model_repec.predict(new_input)  # Predict the label for the new instance (F, I, R or M)\n",
        "\n",
        "if label == 'F':\n",
        "  print('International Economics')\n",
        "elif label == 'I':\n",
        "  print('Health, Education, and Welfare')\n",
        "elif label == 'R':\n",
        "  print('Urban, Rural, Regional, Real Estate, and Transportation Economics')\n",
        "elif label == 'M':\n",
        "  print('Business Administration and Business Economics | Marketing | Accounting | Personnel Economics')\n",
        "else:\n",
        "  print('Unknown class')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjJfjcStqsBA"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZIwuhk8qtk8"
      },
      "source": [
        "# Test with titles instead of abstracts\n",
        "# Tip: corpus = data['title']\n",
        "\n",
        "# Try using different n-gram sizes\n",
        "# Tip: vectorizer = TfidfVectorizer(ngram_range=(1,2))  # Uses 1-grams and 2-grams\n",
        "\n",
        "# Try using TF weighting schema\n",
        "# Tip: vectorizer = CountVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G1GRsddqMEa"
      },
      "source": [
        "## Example 2: sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt3xZe9cuksC"
      },
      "source": [
        "# Check the first lines of the file containing cell phones opinions\n",
        "\n",
        "!head cell_phones.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0mrXTXMuoyI"
      },
      "source": [
        "# Loading data from file\n",
        "\n",
        "data = pd.read_csv('cell_phones.csv')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFg9jkd2uyrO"
      },
      "source": [
        "# Extract the comments and labels\n",
        "\n",
        "corpus = data['content']  # Store the comments\n",
        "y = data['opinion']  # Store positive or negative labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PLd3TOFuyrP"
      },
      "source": [
        "# Plot the classes\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.countplot(x=y)\n",
        "plt.show()\n",
        "\n",
        "# POS: positive opinion\n",
        "# NEG: negative opinion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3wtEzENuyrR"
      },
      "source": [
        "# Preprocessing\n",
        "# Re-use the 'normalise' function\n",
        "\n",
        "corpus_normalised = corpus.map(normalise)\n",
        "corpus_normalised"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yGJDtwyuyrU"
      },
      "source": [
        "# Use the 'classify' function as before\n",
        "# Possible values for model name: DT, KNN, MLP, NB, SVM\n",
        "# Possible values for evaluation type: split, cv\n",
        "\n",
        "model_phones, vectorizer_phones = classify(corpus, 'SVM', 'split')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tBUi_DpuyrV"
      },
      "source": [
        "# Prediction\n",
        "\n",
        "new_input = ['I love this phone!!']\n",
        "new_input = vectorizer_phones.transform(new_input)\n",
        "label = model_phones.predict(new_input)  # Predict the label for the new instance (POS o NEG)\n",
        "\n",
        "if label == 'POS':\n",
        "  print('Positive opinion')\n",
        "elif label == 'NEG':\n",
        "  print('Negative opinion')\n",
        "else:\n",
        "  print('Unknown class')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX3Y3HRY110Z"
      },
      "source": [
        "### Exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T58yyl0v180n"
      },
      "source": [
        "# Create a wordcloud of positive opinions\n",
        "# Tip: data = data[data['opinion'] == 'POS']\n",
        "# Tip: from wordcloud import WordCloud  # Required library"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2xOmNsq3YGk"
      },
      "source": [
        "# Create a wordcloud of negative opinions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers"
      ],
      "metadata": {
        "id": "Gl9i-QyFe_vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü§ó [Transformers](https://huggingface.co/transformers/) library provides general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet...) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with deep interoperability between Jax, PyTorch and TensorFlow.\n",
        "\n",
        "There are more than 30,000 pre-trained [models](https://huggingface.co/models) and 2,000 [datasets](https://huggingface.co/datasets) available in their web page, covering tenths of different tasks in more than 100 languages.\n",
        "\n",
        "This demo exemplifies the use of [pipelines](https://huggingface.co/transformers/main_classes/pipelines.html). These pipelines are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks, including Named Entity Recognition, Masked Language Modeling, Sentiment Analysis, and Question Answering.\n",
        "\n",
        "The following examples are inspired in the ü§ó Transformers library [course](https://huggingface.co/course/chapter1/3?fw=pt)."
      ],
      "metadata": {
        "id": "sCF3nU0jfCpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Transformers library\n",
        "\n",
        "!pip install transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "KOZe3xsUgrfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline  # Import Transformer models"
      ],
      "metadata": {
        "id": "QbSWZFjjgv4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment analysis\n",
        "Classify a sentence according to positive or negative sentiments."
      ],
      "metadata": {
        "id": "Taz4rb8ZfLtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the sentiment analysis model ('distilbert-base-uncased-finetuned-sst-2-english' by default)\n",
        "\n",
        "model = pipeline('sentiment-analysis')"
      ],
      "metadata": {
        "id": "lAlYAFCPfPud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try it!\n",
        "\n",
        "model('This is the best course I have ever attended in my life. Praise to David!')"
      ],
      "metadata": {
        "id": "l9EXDyijfTw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero-shot classification\n",
        "Classify text according to a set of given labels."
      ],
      "metadata": {
        "id": "ZdioyksGfXs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the zero-shot classification model ('facebook/bart-large-mnli' by default)\n",
        "\n",
        "model = pipeline('zero-shot-classification')"
      ],
      "metadata": {
        "id": "wat__uypfVH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try it!\n",
        "\n",
        "model('This lecture is about Natural Language Processing', candidate_labels=['education', 'politics', 'business', 'sports'])"
      ],
      "metadata": {
        "id": "g0bO7QjMfcA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text generation\n",
        "Predict the words that will follow a specified text prompt, creating a coherent portion of text that is a continuation from the given context."
      ],
      "metadata": {
        "id": "Qtqcg-QKfhVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the text generation model ('gpt2' by default)\n",
        "\n",
        "model = pipeline('text-generation')"
      ],
      "metadata": {
        "id": "zn-TQ6Cpfeic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try it! (you will get a different output each time)\n",
        "\n",
        "model('I opened the door and found')"
      ],
      "metadata": {
        "id": "UJ4NVSy-f2dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tyr it tuning some parameters (maximum length generated and number of returned sentences)!\n",
        "\n",
        "model('The book was amazing', max_length=40, num_return_sequences=3)"
      ],
      "metadata": {
        "id": "CFPICeFFf6vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Masked language modelling\n",
        "Mask a token in a sequence with a masking token, and prompt the model to fill that mask with an appropriate token."
      ],
      "metadata": {
        "id": "Yr-GZY3lf-cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the masked language modelling model ('distilroberta-base' by default)\n",
        "\n",
        "model = pipeline('fill-mask')"
      ],
      "metadata": {
        "id": "YC7C7NGGf_RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try it (returning the 'top_k' words)!\n",
        "\n",
        "model('I <mask> this lecture.', top_k=5)"
      ],
      "metadata": {
        "id": "0Ocx-lWEgCMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Named entity recognition\n",
        "Classify tokens according to a class (e.g. person, organisation or location)."
      ],
      "metadata": {
        "id": "cU8quD_LgHjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the named entity recognition model ('dbmdz/bert-large-cased-finetuned-conll03-english' by default)\n",
        "\n",
        "model = pipeline('ner', grouped_entities=True)"
      ],
      "metadata": {
        "id": "DlOc3-DTgKcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try it!\n",
        "\n",
        "model('My name is David and I live in Spain.')"
      ],
      "metadata": {
        "id": "BmL2YoZbgNMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question answering\n",
        "Extract an answer from a text given a question."
      ],
      "metadata": {
        "id": "BH7RffUugPm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the question answering model ('distilbert-base-cased-distilled-squad' by default)\n",
        "\n",
        "model = pipeline('question-answering')"
      ],
      "metadata": {
        "id": "NPKGpFVYgSM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try it!\n",
        "\n",
        "model(question='Where do I work?', context='My name is David and I work really hard at the Unviersity of Alicante')"
      ],
      "metadata": {
        "id": "0F53SxXCgVHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Machine translation\n",
        "Translate from one language to another."
      ],
      "metadata": {
        "id": "cucNCaHzgZje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the machine translation model from ES to EN ('Helsinki-NLP/opus-mt-es-en')\n",
        "# Try different models changing 'Helsinki-NLP/opus-mt-{src}-{tgt}' (src = source language, tgt = target)\n",
        "\n",
        "model = pipeline('translation', model='Helsinki-NLP/opus-mt-es-en')"
      ],
      "metadata": {
        "id": "ZtfCqYhigac5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try it!\n",
        "\n",
        "model('Ojal√° el pr√≥ximo a√±o pueda ir a Alicante')"
      ],
      "metadata": {
        "id": "11ztgRl_ge5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuGoggVzTv4_"
      },
      "source": [
        "# References\n",
        "\n",
        "* [RePEC](http://www.repec.org/)\n",
        "* [JEL Classification System](https://www.aeaweb.org/econlit/jelCodes.php?view=jel)\n",
        "* [Hugging Face](https://huggingface.co/)\n"
      ]
    }
  ]
}